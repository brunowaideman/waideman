{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ff4ab-91fc-46c7-b0c0-4c533526193b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting face detector...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mss\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "from Gaze import Detector, Predictor\n",
    "from Models import FullModel\n",
    "from utils import get_config, clamp_value\n",
    "\n",
    "\n",
    "# Read config.ini file\n",
    "SETTINGS, COLOURS, EYETRACKER, TF = get_config(\"config.ini\")\n",
    "\n",
    "with mss.mss() as sct:\n",
    "    mon = sct.monitors[EYETRACKER[\"monitor_num\"]]\n",
    "    w, h = mon[\"width\"], mon[\"height\"]\n",
    "    monitor = {\n",
    "        \"top\": mon[\"top\"],\n",
    "        \"left\": mon[\"left\"],\n",
    "        \"width\": w,\n",
    "        \"height\": h,\n",
    "        \"mon\": EYETRACKER[\"monitor_num\"],\n",
    "    }\n",
    "\n",
    "    # Load trained model\n",
    "    detector = Detector(output_size=SETTINGS[\"image_size\"])\n",
    "    predictor = Predictor(\n",
    "        FullModel,\n",
    "        model_data=\"trained_models/eyetracking_model.pt\",\n",
    "        config_file=\"trained_models/eyetracking_config.json\",\n",
    "    )\n",
    "    screen_errors = region_map = np.load(\"trained_models/eyetracking_errors.npy\")\n",
    "\n",
    "    track_x = deque(\n",
    "        [0] * SETTINGS[\"avg_window_length\"], maxlen=SETTINGS[\"avg_window_length\"]\n",
    "    )\n",
    "    track_y = deque(\n",
    "        [0] * SETTINGS[\"avg_window_length\"], maxlen=SETTINGS[\"avg_window_length\"]\n",
    "    )\n",
    "    track_error = deque(\n",
    "        [0] * (SETTINGS[\"avg_window_length\"] * 2),\n",
    "        maxlen=SETTINGS[\"avg_window_length\"] * 2,\n",
    "    )\n",
    "\n",
    "    videoWriter = None\n",
    "    if EYETRACKER[\"write_to_disk\"]:\n",
    "        # FIXME: fix video codec on windows\n",
    "        date_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"avc1\")\n",
    "        videoWriter = cv2.VideoWriter(\n",
    "            \"media/recordings/{}.mp4\".format(date_time),\n",
    "            fourcc,\n",
    "            EYETRACKER[\"tracker_frame_rate\"],\n",
    "            (\n",
    "                int(w * EYETRACKER[\"screen_capture_scale\"]),\n",
    "                int(h * EYETRACKER[\"screen_capture_scale\"]),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    last_time = time.time()\n",
    "    while True:\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # wait for escape key\n",
    "            detector.close()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "        cur_time = time.time()\n",
    "\n",
    "        if (cur_time - last_time) >= 1 / EYETRACKER[\"tracker_frame_rate\"]:\n",
    "            fps = 1 / (cur_time - last_time)\n",
    "            last_time = cur_time\n",
    "\n",
    "            # Get camera data\n",
    "            l_eye, r_eye, face, face_align, head_pos, angle = detector.get_frame()\n",
    "\n",
    "            # Get screenshot\n",
    "            screenshot = np.array(sct.grab(monitor))\n",
    "            overlay = screenshot.copy()\n",
    "\n",
    "            # Overlays\n",
    "            x_hat, y_hat = predictor.predict(\n",
    "                face, l_eye, r_eye, head_pos, head_angle=angle\n",
    "            )\n",
    "\n",
    "            track_x.append(x_hat)\n",
    "            track_y.append(y_hat)\n",
    "\n",
    "            x_hat_clamp = clamp_value(x_hat, w)\n",
    "            y_hat_clamp = clamp_value(y_hat, h)\n",
    "            error = screen_errors[int(x_hat_clamp) - 1][int(y_hat_clamp) - 1]\n",
    "            track_error.append(error * 0.75)\n",
    "\n",
    "            weights = np.arange(1, SETTINGS[\"avg_window_length\"] + 1)\n",
    "            weights_error = np.arange(1, (SETTINGS[\"avg_window_length\"] * 2) + 1)\n",
    "\n",
    "            cv2.circle(\n",
    "                overlay,\n",
    "                (\n",
    "                    int(np.average(track_x, weights=weights)),\n",
    "                    int(np.average(track_y, weights=weights)),\n",
    "                ),\n",
    "                int(np.average(track_error, weights=weights_error)),\n",
    "                (255, 255, 255, 50),\n",
    "                -1,\n",
    "            )\n",
    "\n",
    "            cv2.circle(\n",
    "                screenshot,\n",
    "                (\n",
    "                    int(np.average(track_x, weights=weights)),\n",
    "                    int(np.average(track_y, weights=weights)),\n",
    "                ),\n",
    "                int(np.average(track_error, weights=weights_error)),\n",
    "                COLOURS[\"green\"],\n",
    "                5,\n",
    "            )\n",
    "\n",
    "            screenshot = cv2.addWeighted(overlay, 0.3, screenshot, 0.7, 0)\n",
    "\n",
    "            cv2.putText(\n",
    "                screenshot,\n",
    "                \"fps: {}\".format(round(fps, 2)),\n",
    "                (0, h),\n",
    "                cv2.FONT_HERSHEY_PLAIN,\n",
    "                2,\n",
    "                COLOURS[\"green\"],\n",
    "            )\n",
    "\n",
    "            if EYETRACKER[\"show_webcam\"]:\n",
    "                large_size = SETTINGS[\"image_size\"] * 2\n",
    "\n",
    "                screenshot[0:large_size, 0:large_size, 0:3] = cv2.resize(\n",
    "                    face_align, (large_size, large_size)\n",
    "                )\n",
    "\n",
    "                screenshot[\n",
    "                    0:large_size,\n",
    "                    large_size : large_size * 2,\n",
    "                    0:3,\n",
    "                ] = cv2.resize(\n",
    "                    np.repeat(head_pos[:, :, np.newaxis], 3, axis=2),\n",
    "                    (large_size, large_size),\n",
    "                )\n",
    "\n",
    "                screenshot[\n",
    "                    large_size : large_size * 2,\n",
    "                    0:large_size,\n",
    "                    0:3,\n",
    "                ] = cv2.resize(l_eye, (large_size, large_size))\n",
    "\n",
    "                screenshot[\n",
    "                    large_size : large_size * 2,\n",
    "                    large_size : large_size * 2,\n",
    "                    0:3,\n",
    "                ] = cv2.resize(r_eye, (large_size, large_size))\n",
    "\n",
    "            # Resize and write frame\n",
    "            screenshot = cv2.resize(\n",
    "                screenshot,\n",
    "                (\n",
    "                    int(w * EYETRACKER[\"screen_capture_scale\"]),\n",
    "                    int(h * EYETRACKER[\"screen_capture_scale\"]),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            cv2.imshow(\"Eyetracker\", screenshot)\n",
    "            # cv2.imshow(\"Webcam\", face)\n",
    "\n",
    "            if EYETRACKER[\"write_to_disk\"]:\n",
    "                videoWriter.write(screenshot)\n",
    "\n",
    "    if EYETRACKER[\"write_to_disk\"]:\n",
    "        videoWriter.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec713ea-714a-4808-b10c-3c4dbf1907bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
